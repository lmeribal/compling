{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание № 2. Мешок слов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 1 (3 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У векторайзеров в sklearn есть встроенная токенизация на регулярных выражениях. Найдите способо заменить её на кастомную токенизацию"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучите векторайзер с дефолтной токенизацией и с токенизацией razdel.tokenize. Обучите классификатор с каждым из векторизаторов. Сравните метрики и выберете победителя. \n",
    "\n",
    "(в вашей тетрадке должен быть код обучения и все метрики; если вы сдаете в .py файлах то сохраните полученные метрики в отдельном файле или в комментариях)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Верблюдов-то за что? Дебилы, бл...\\n</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Хохлы, это отдушина затюканого россиянина, мол...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Собаке - собачья смерть\\n</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Страницу обнови, дебил. Это тоже не оскорблени...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>тебя не убедил 6-страничный пдф в том, что Скр...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  toxic\n",
       "0               Верблюдов-то за что? Дебилы, бл...\\n    1.0\n",
       "1  Хохлы, это отдушина затюканого россиянина, мол...    1.0\n",
       "2                          Собаке - собачья смерть\\n    1.0\n",
       "3  Страницу обнови, дебил. Это тоже не оскорблени...    1.0\n",
       "4  тебя не убедил 6-страничный пдф в том, что Скр...    1.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('labeled.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    9586\n",
       "1.0    4826\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['toxic'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from razdel import tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(data, test_size=0.1, shuffle=True)\n",
    "train.reset_index(inplace=True)\n",
    "test.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Стандартная токенизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_default = CountVectorizer()\n",
    "\n",
    "X_1 = cv_default.fit_transform(train.comment)\n",
    "X_test_1 = cv_default.transform(test.comment)\n",
    "\n",
    "y_1 = train.toxic.values\n",
    "y_test_1 = test.toxic.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf_1 = LogisticRegression(C=0.1, class_weight='balanced')\n",
    "clf_1.fit(X_1, y_1)\n",
    "\n",
    "preds_1 = clf.predict(X_test_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Токенизация razdel.tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_with_tokenizer = CountVectorizer(tokenizer=lambda text: [_.text for _ in list(tokenize(text))])\n",
    "\n",
    "X_2 = cv_with_tokenizer.fit_transform(train.comment)\n",
    "X_test_2 = cv_with_tokenizer.transform(test.comment)\n",
    "\n",
    "y_2 = train.toxic.values\n",
    "y_test_2 = test.toxic.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(C=0.1, class_weight='balanced')\n",
    "clf.fit(X_2, y_2)\n",
    "\n",
    "preds_2 = clf.predict(X_test_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сравнение результатов на метриках"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Стандартная токенизация:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.85      0.88       960\n",
      "         1.0       0.73      0.82      0.77       482\n",
      "\n",
      "    accuracy                           0.84      1442\n",
      "   macro avg       0.82      0.84      0.83      1442\n",
      "weighted avg       0.85      0.84      0.84      1442\n",
      "\n",
      "F1: 0.7746341463414634\n",
      "\n",
      "Токенизация razdel.tokenize:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.85      0.88       960\n",
      "         1.0       0.73      0.84      0.78       482\n",
      "\n",
      "    accuracy                           0.84      1442\n",
      "   macro avg       0.82      0.84      0.83      1442\n",
      "weighted avg       0.85      0.84      0.85      1442\n",
      "\n",
      "F1: 0.7833655705996132\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "print(\"Стандартная токенизация:\\n\", classification_report(y_test_1, preds_1))\n",
    "print(f\"F1: {f1_score(y_test_1, preds_1)}\")\n",
    "print(\"\\nТокенизация razdel.tokenize:\\n\", classification_report(y_test_2, preds_2))\n",
    "print(f\"F1: {f1_score(y_test_2, preds_2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Общий F1 выше с токенизацией razdel.tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 2 (3 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразуйте таблицу с абсолютными частотностями в семинарской тетрадке в таблицу с tfidf значениями. (Таблица - https://i.ibb.co/r5Nc2HC/abs-bow.jpg) Формула tfidf есть в семинаре на картнике с пояснениями на английском. \n",
    "Считать нужно в питоне. Формат итоговой таблицы может быть любым, главное, чтобы был код и можно было воспроизвести вычисления. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "docs = [\n",
    "    \"я и ты\",\n",
    "    \"ты и я\",\n",
    "    \"я, я и только я\",\n",
    "    \"только не я\",\n",
    "    \"он\"\n",
    "]\n",
    "\n",
    "tokens = [\n",
    "    \"я\", \"ты\", \"и\", \"только\", \"не\", \"он\"\n",
    "]\n",
    "\n",
    "def return_tf(term, document):\n",
    "    return(document.count(term))\n",
    "\n",
    "def return_idf(term, docs):\n",
    "    df = 0\n",
    "    for d in docs:\n",
    "        if term in d:\n",
    "            df += 1\n",
    "            continue\n",
    "    return np.log(len(docs) / df)\n",
    "\n",
    "def return_tf_x_idf(term, document, docs):\n",
    "    return return_tf(term, document) * return_idf(term, docs)\n",
    "\n",
    "table = pd.DataFrame()\n",
    "\n",
    "for t in tokens:\n",
    "    tmp = []\n",
    "    for d in docs:\n",
    "        tmp.append(return_tf_x_idf(t, d, docs))\n",
    "    table[t] = tmp\n",
    "\n",
    "table.index = docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>я</th>\n",
       "      <th>ты</th>\n",
       "      <th>и</th>\n",
       "      <th>только</th>\n",
       "      <th>не</th>\n",
       "      <th>он</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>я и ты</th>\n",
       "      <td>0.223144</td>\n",
       "      <td>0.916291</td>\n",
       "      <td>0.510826</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ты и я</th>\n",
       "      <td>0.223144</td>\n",
       "      <td>0.916291</td>\n",
       "      <td>0.510826</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>я, я и только я</th>\n",
       "      <td>0.669431</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.510826</td>\n",
       "      <td>0.916291</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>только не я</th>\n",
       "      <td>0.223144</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.916291</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>он</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.609438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        я        ты         и    только        не        он\n",
       "я и ты           0.223144  0.916291  0.510826  0.000000  0.000000  0.000000\n",
       "ты и я           0.223144  0.916291  0.510826  0.000000  0.000000  0.000000\n",
       "я, я и только я  0.669431  0.000000  0.510826  0.916291  0.000000  0.000000\n",
       "только не я      0.223144  0.000000  0.000000  0.916291  1.609438  0.000000\n",
       "он               0.000000  0.000000  0.000000  0.000000  0.000000  1.609438"
      ]
     },
     "execution_count": 561,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 3 (2 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучите 2 любых разных классификатора из семинара. Предскажите токсичность для текстов из тестовой выборки (используйте одну и ту же выборку для обоих классификаторов) и найдите 10 самых токсичных для каждого из классификаторов. Сравните получаемые тексты - какие тексты совпадают, какие отличаются, правда ли тексты токсичные?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Требования к классификаторам:   \n",
    "а) один должен использовать CountVectorizer, другой TfidfVectorizer  \n",
    "б) у векторазера должны быть вручную заданы как минимум 5 параметров  \n",
    "в) у классификатора должно быть задано вручную как минимум 2 параметра  \n",
    "г)  f1 мера каждого из классификаторов должна быть минимум 0.75  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer + KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from pymystem3 import Mystem\n",
    "\n",
    "russian_stopwords = stopwords.words(\"russian\")\n",
    "russian_stopwords.extend(['весь', 'свой', 'это', 'тебе', 'очень', 'просто', 'ещё', 'почему'])\n",
    "\n",
    "mystem = Mystem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def preprocessor(string):\n",
    "    lemmatized = mystem.lemmatize(string)\n",
    "    result = []\n",
    "    for item in lemmatized:\n",
    "        if not re.match(\"\\d|\\W\", item):\n",
    "            result.append(item)\n",
    "    return \" \".join(result)\n",
    "\n",
    "cv = CountVectorizer(\n",
    "    tokenizer=lambda text: [_.text for _ in list(tokenize(text))],\n",
    "    min_df=30,\n",
    "    ngram_range=(1,2),    \n",
    "    preprocessor=preprocessor,\n",
    "    stop_words=russian_stopwords\n",
    ")\n",
    "\n",
    "X = cv.fit_transform(train.comment)\n",
    "X_test = cv.transform(test.comment)\n",
    "\n",
    "y = train.toxic.values\n",
    "y_test = test.toxic.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.83      0.87      1056\n",
      "         1.0       0.62      0.77      0.69       386\n",
      "\n",
      "    accuracy                           0.81      1442\n",
      "   macro avg       0.76      0.80      0.78      1442\n",
      "weighted avg       0.83      0.81      0.82      1442\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/naive_bayes.py:485: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "clf = MultinomialNB(alpha=0, fit_prior=True)\n",
    "\n",
    "clf.fit(X, y)\n",
    "\n",
    "preds = clf.predict(X_test)\n",
    "preds_proba = clf.predict_proba(X_test)\n",
    "\n",
    "print(classification_report(preds, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "test['preds'] = preds\n",
    "test['probs_0'] = [el[0] for el in preds_proba]\n",
    "test['probs_1'] = [el[1] for el in preds_proba]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>comment</th>\n",
       "      <th>toxic</th>\n",
       "      <th>preds</th>\n",
       "      <th>probs</th>\n",
       "      <th>probs_0</th>\n",
       "      <th>probs_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>3049</td>\n",
       "      <td>открытому пиздабольству детектятся именно русс...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[9.826090456951407e-07, 0.9999990173909548]</td>\n",
       "      <td>6.593971e-17</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>964</th>\n",
       "      <td>2251</td>\n",
       "      <td>Несправедливый раздел Русские себе почти всё з...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[4.2482473266546404e-08, 0.9999999575175034]</td>\n",
       "      <td>1.284574e-17</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>666</td>\n",
       "      <td>Лол, совковая пидораха полыхает, но аргументов...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[7.921800107823326e-09, 0.9999999920782017]</td>\n",
       "      <td>6.114727e-29</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>14253</td>\n",
       "      <td>Надо просто Тарасов-пидорашек из по выгнать, т...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[6.24795951070416e-06, 0.9999937520404885]</td>\n",
       "      <td>3.591614e-16</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>886</td>\n",
       "      <td>Хохлы - отражение русни в кривом зеркале, вобр...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[1.2133374498764735e-08, 0.9999999878666302]</td>\n",
       "      <td>1.365690e-18</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>449</td>\n",
       "      <td>2:30 - малолетнему дебилу открылся дзен и приш...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[4.3474283675502336e-07, 0.9999995652571648]</td>\n",
       "      <td>2.372544e-17</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>925</th>\n",
       "      <td>6096</td>\n",
       "      <td>Какие же пиндосы дегенераты, пиздец просто.\\n</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.0007222981992673935, 0.9992777018007342]</td>\n",
       "      <td>9.366644e-14</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437</th>\n",
       "      <td>14053</td>\n",
       "      <td>Чушкаина это и есть пидорашка в ее самом худше...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.0015451634077258399, 0.9984548365922702]</td>\n",
       "      <td>1.554988e-13</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>2163</td>\n",
       "      <td>ВЕСЬ МИР С НАМИ - прохрюкала нищая пидорашка, ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.0024115181276831, 0.9975884818723155]</td>\n",
       "      <td>2.232096e-13</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>5558</td>\n",
       "      <td>Политачеры, вы что ебанутые? Какого хуя я вижу...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[9.393071583707656e-13, 0.9999999999990337]</td>\n",
       "      <td>2.058298e-13</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                                            comment  toxic  preds  \\\n",
       "526    3049  открытому пиздабольству детектятся именно русс...    1.0    1.0   \n",
       "964    2251  Несправедливый раздел Русские себе почти всё з...    1.0    1.0   \n",
       "236     666  Лол, совковая пидораха полыхает, но аргументов...    1.0    1.0   \n",
       "1000  14253  Надо просто Тарасов-пидорашек из по выгнать, т...    1.0    1.0   \n",
       "256     886  Хохлы - отражение русни в кривом зеркале, вобр...    1.0    1.0   \n",
       "706     449  2:30 - малолетнему дебилу открылся дзен и приш...    1.0    1.0   \n",
       "925    6096      Какие же пиндосы дегенераты, пиздец просто.\\n    1.0    1.0   \n",
       "1437  14053  Чушкаина это и есть пидорашка в ее самом худше...    1.0    1.0   \n",
       "540    2163  ВЕСЬ МИР С НАМИ - прохрюкала нищая пидорашка, ...    1.0    1.0   \n",
       "318    5558  Политачеры, вы что ебанутые? Какого хуя я вижу...    1.0    1.0   \n",
       "\n",
       "                                             probs       probs_0  probs_1  \n",
       "526    [9.826090456951407e-07, 0.9999990173909548]  6.593971e-17      1.0  \n",
       "964   [4.2482473266546404e-08, 0.9999999575175034]  1.284574e-17      1.0  \n",
       "236    [7.921800107823326e-09, 0.9999999920782017]  6.114727e-29      1.0  \n",
       "1000    [6.24795951070416e-06, 0.9999937520404885]  3.591614e-16      1.0  \n",
       "256   [1.2133374498764735e-08, 0.9999999878666302]  1.365690e-18      1.0  \n",
       "706   [4.3474283675502336e-07, 0.9999995652571648]  2.372544e-17      1.0  \n",
       "925    [0.0007222981992673935, 0.9992777018007342]  9.366644e-14      1.0  \n",
       "1437   [0.0015451634077258399, 0.9984548365922702]  1.554988e-13      1.0  \n",
       "540       [0.0024115181276831, 0.9975884818723155]  2.232096e-13      1.0  \n",
       "318    [9.393071583707656e-13, 0.9999999999990337]  2.058298e-13      1.0  "
      ]
     },
     "execution_count": 663,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.sort_values(by='probs_1', ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TfidfVectorizer + DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tf = TfidfVectorizer(\n",
    "    preprocessor=preprocessor,\n",
    "    min_df=50,\n",
    "    ngram_range=(1,2), \n",
    "    sublinear_tf=False,\n",
    "    stop_words=russian_stopwords\n",
    ")\n",
    "\n",
    "X = tf.fit_transform(train.comment)\n",
    "X_test = tf.transform(test.comment)\n",
    "\n",
    "y = train.toxic.values\n",
    "y_test = test.toxic.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.84      0.82       919\n",
      "         1.0       0.70      0.64      0.67       523\n",
      "\n",
      "    accuracy                           0.77      1442\n",
      "   macro avg       0.75      0.74      0.75      1442\n",
      "weighted avg       0.77      0.77      0.77      1442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf = DecisionTreeClassifier(\n",
    "    criterion='entropy',\n",
    "    splitter='best'\n",
    ")\n",
    "\n",
    "clf.fit(X, y)\n",
    "preds = clf.predict(X_test)\n",
    "preds_probs = clf.predict_proba(X_test)\n",
    "print(classification_report(preds, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "test['preds'] = preds\n",
    "test['probs_0'] = [el[0] for el in preds_proba]\n",
    "test['probs_1'] = [el[1] for el in preds_proba]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>comment</th>\n",
       "      <th>toxic</th>\n",
       "      <th>preds</th>\n",
       "      <th>probs</th>\n",
       "      <th>probs_0</th>\n",
       "      <th>probs_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>2000</td>\n",
       "      <td>орет с дегенератов постит Сартра Самокритично\\n</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.01096420223704809, 0.9890357977629525]</td>\n",
       "      <td>2.728218e-12</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>925</th>\n",
       "      <td>6096</td>\n",
       "      <td>Какие же пиндосы дегенераты, пиздец просто.\\n</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.0007222981992673935, 0.9992777018007342]</td>\n",
       "      <td>4.967639e-10</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>6235</td>\n",
       "      <td>И НЕ ПОЛНЫЙ ДЕГЕНЕРАТ мечтает о пониленде педо...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.013448656094922842, 0.9865513439050765]</td>\n",
       "      <td>2.590783e-09</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>3049</td>\n",
       "      <td>открытому пиздабольству детектятся именно русс...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[9.826090456951407e-07, 0.9999990173909548]</td>\n",
       "      <td>1.745070e-06</td>\n",
       "      <td>0.999998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>449</td>\n",
       "      <td>2:30 - малолетнему дебилу открылся дзен и приш...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[4.3474283675502336e-07, 0.9999995652571648]</td>\n",
       "      <td>4.911227e-05</td>\n",
       "      <td>0.999951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1169</th>\n",
       "      <td>589</td>\n",
       "      <td>Ебать вы тупые дебилы, ой блять\\n</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[1.3246551106194424e-06, 0.9999986753448907]</td>\n",
       "      <td>1.928192e-03</td>\n",
       "      <td>0.998072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>2978</td>\n",
       "      <td>Хохлы одним своим существованием оскорбляют ру...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[8.564699776766148e-06, 0.9999914353002229]</td>\n",
       "      <td>2.082525e-03</td>\n",
       "      <td>0.997917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>14356</td>\n",
       "      <td>ДА КАКОГО ЕБАНОГО ХУЯ МНЕ ТЕПЕРЬ ЮТУБ РЕКОМЕНД...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[1.303835092140478e-12, 0.9999999999986926]</td>\n",
       "      <td>2.391622e-03</td>\n",
       "      <td>0.997608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>6497</td>\n",
       "      <td>null 0 Сука, какие же коммибляди тупые.\\n</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.0008319029025564182, 0.9991680970974438]</td>\n",
       "      <td>2.422966e-03</td>\n",
       "      <td>0.997577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>2080</td>\n",
       "      <td>НУ ВСЕ, сука говго щас модераторам пишу твою т...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[2.920826301472967e-07, 0.9999997079173681]</td>\n",
       "      <td>4.151330e-03</td>\n",
       "      <td>0.995849</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                                            comment  toxic  preds  \\\n",
       "299    2000    орет с дегенератов постит Сартра Самокритично\\n    1.0    1.0   \n",
       "925    6096      Какие же пиндосы дегенераты, пиздец просто.\\n    1.0    1.0   \n",
       "735    6235  И НЕ ПОЛНЫЙ ДЕГЕНЕРАТ мечтает о пониленде педо...    1.0    1.0   \n",
       "526    3049  открытому пиздабольству детектятся именно русс...    1.0    1.0   \n",
       "706     449  2:30 - малолетнему дебилу открылся дзен и приш...    1.0    1.0   \n",
       "1169    589                  Ебать вы тупые дебилы, ой блять\\n    1.0    1.0   \n",
       "1006   2978  Хохлы одним своим существованием оскорбляют ру...    1.0    1.0   \n",
       "373   14356  ДА КАКОГО ЕБАНОГО ХУЯ МНЕ ТЕПЕРЬ ЮТУБ РЕКОМЕНД...    1.0    1.0   \n",
       "36     6497          null 0 Сука, какие же коммибляди тупые.\\n    1.0    1.0   \n",
       "333    2080  НУ ВСЕ, сука говго щас модераторам пишу твою т...    1.0    1.0   \n",
       "\n",
       "                                             probs       probs_0   probs_1  \n",
       "299      [0.01096420223704809, 0.9890357977629525]  2.728218e-12  1.000000  \n",
       "925    [0.0007222981992673935, 0.9992777018007342]  4.967639e-10  1.000000  \n",
       "735     [0.013448656094922842, 0.9865513439050765]  2.590783e-09  1.000000  \n",
       "526    [9.826090456951407e-07, 0.9999990173909548]  1.745070e-06  0.999998  \n",
       "706   [4.3474283675502336e-07, 0.9999995652571648]  4.911227e-05  0.999951  \n",
       "1169  [1.3246551106194424e-06, 0.9999986753448907]  1.928192e-03  0.998072  \n",
       "1006   [8.564699776766148e-06, 0.9999914353002229]  2.082525e-03  0.997917  \n",
       "373    [1.303835092140478e-12, 0.9999999999986926]  2.391622e-03  0.997608  \n",
       "36     [0.0008319029025564182, 0.9991680970974438]  2.422966e-03  0.997577  \n",
       "333    [2.920826301472967e-07, 0.9999997079173681]  4.151330e-03  0.995849  "
      ]
     },
     "execution_count": 658,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.sort_values(by='probs_1', ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В оба результата попали только токсичные комментарии. Комментарии между двумя таблицами практически отличны, но везде много ненормативной лексики. Есть общие комментарии – например, \"Какие же пиндосы дегенераты, пиздец просто.\" встречается в обоих таблицах"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Задание 4 (2 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для классификаторов LogisticRegression, Decision Trees, Naive Bayes, Random Forest найдите способ извлечь важность признаков для предсказания токсичного класса. Сопоставьте полученные числа со словами (или нграммами) в словаре и найдите топ - 5 \"токсичных\" слов для каждого из классификаторов. \n",
    "\n",
    "Важное требование: в топе не должно быть стоп-слов. Для этого вам нужно будет правильным образом настроить векторизацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "\n",
    "tf = TfidfVectorizer(\n",
    "    max_df=0.8,\n",
    "    stop_words=russian_stopwords\n",
    ")\n",
    "\n",
    "X = tf.fit_transform(train.comment)\n",
    "\n",
    "def return_top5_toxic_words(clf):\n",
    "    clf.fit(X, y)\n",
    "    feature_importance = pd.DataFrame()\n",
    "    feature_importance['feature'] = tf.get_feature_names()\n",
    "    if isinstance(clf, sklearn.linear_model.logistic.LogisticRegression) or isinstance(clf, sklearn.naive_bayes.MultinomialNB):\n",
    "        feature_importance['importance'] = clf.coef_[0]\n",
    "    else:    \n",
    "        feature_importance['importance'] = clf.feature_importances_\n",
    "    return feature_importance.sort_values(by='importance', ascending=False)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60625</th>\n",
       "      <td>хохлы</td>\n",
       "      <td>0.016008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29486</th>\n",
       "      <td>нахуй</td>\n",
       "      <td>0.011975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60593</th>\n",
       "      <td>хохлов</td>\n",
       "      <td>0.011692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5308</th>\n",
       "      <td>блядь</td>\n",
       "      <td>0.008171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5310</th>\n",
       "      <td>блять</td>\n",
       "      <td>0.007217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature  importance\n",
       "60625   хохлы    0.016008\n",
       "29486   нахуй    0.011975\n",
       "60593  хохлов    0.011692\n",
       "5308    блядь    0.008171\n",
       "5310    блять    0.007217"
      ]
     },
     "execution_count": 620,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "return_top5_toxic_words(DecisionTreeClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60622</th>\n",
       "      <td>хохлы</td>\n",
       "      <td>-7.851612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60590</th>\n",
       "      <td>хохлов</td>\n",
       "      <td>-7.964018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29485</th>\n",
       "      <td>нахуй</td>\n",
       "      <td>-8.131140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60852</th>\n",
       "      <td>хуй</td>\n",
       "      <td>-8.291794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5308</th>\n",
       "      <td>блядь</td>\n",
       "      <td>-8.319525</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature  importance\n",
       "60622   хохлы   -7.851612\n",
       "60590  хохлов   -7.964018\n",
       "29485   нахуй   -8.131140\n",
       "60852     хуй   -8.291794\n",
       "5308    блядь   -8.319525"
      ]
     },
     "execution_count": 640,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.naive_bayes.MultinomialNB\n",
    "\n",
    "return_top5_toxic_words(MultinomialNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60625</th>\n",
       "      <td>хохлы</td>\n",
       "      <td>4.876556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60593</th>\n",
       "      <td>хохлов</td>\n",
       "      <td>4.466427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29486</th>\n",
       "      <td>нахуй</td>\n",
       "      <td>3.773715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37243</th>\n",
       "      <td>пиздец</td>\n",
       "      <td>3.275592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5310</th>\n",
       "      <td>блять</td>\n",
       "      <td>3.241132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature  importance\n",
       "60625   хохлы    4.876556\n",
       "60593  хохлов    4.466427\n",
       "29486   нахуй    3.773715\n",
       "37243  пиздец    3.275592\n",
       "5310    блять    3.241132"
      ]
     },
     "execution_count": 630,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "return_top5_toxic_words(LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60625</th>\n",
       "      <td>хохлы</td>\n",
       "      <td>0.009268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60593</th>\n",
       "      <td>хохлов</td>\n",
       "      <td>0.007300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29486</th>\n",
       "      <td>нахуй</td>\n",
       "      <td>0.006744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5308</th>\n",
       "      <td>блядь</td>\n",
       "      <td>0.005668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37243</th>\n",
       "      <td>пиздец</td>\n",
       "      <td>0.004189</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature  importance\n",
       "60625   хохлы    0.009268\n",
       "60593  хохлов    0.007300\n",
       "29486   нахуй    0.006744\n",
       "5308    блядь    0.005668\n",
       "37243  пиздец    0.004189"
      ]
     },
     "execution_count": 631,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "return_top5_toxic_words(RandomForestClassifier())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
