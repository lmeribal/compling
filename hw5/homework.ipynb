{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание  № 5. Матричные разложения/Тематическое моделирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/pymorphy2/units/base.py:70: DeprecationWarning: inspect.getargspec() is deprecated since Python 3.0, use inspect.signature() or inspect.getfullargspec()\n",
      "  args, varargs, kw, default = inspect.getargspec(cls.__init__)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/pymorphy2/units/base.py:70: DeprecationWarning: inspect.getargspec() is deprecated since Python 3.0, use inspect.signature() or inspect.getfullargspec()\n",
      "  args, varargs, kw, default = inspect.getargspec(cls.__init__)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/pymorphy2/units/base.py:70: DeprecationWarning: inspect.getargspec() is deprecated since Python 3.0, use inspect.signature() or inspect.getfullargspec()\n",
      "  args, varargs, kw, default = inspect.getargspec(cls.__init__)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/pymorphy2/units/base.py:70: DeprecationWarning: inspect.getargspec() is deprecated since Python 3.0, use inspect.signature() or inspect.getfullargspec()\n",
      "  args, varargs, kw, default = inspect.getargspec(cls.__init__)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/pymorphy2/units/base.py:70: DeprecationWarning: inspect.getargspec() is deprecated since Python 3.0, use inspect.signature() or inspect.getfullargspec()\n",
      "  args, varargs, kw, default = inspect.getargspec(cls.__init__)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/pymorphy2/units/base.py:70: DeprecationWarning: inspect.getargspec() is deprecated since Python 3.0, use inspect.signature() or inspect.getfullargspec()\n",
      "  args, varargs, kw, default = inspect.getargspec(cls.__init__)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/pymorphy2/units/base.py:70: DeprecationWarning: inspect.getargspec() is deprecated since Python 3.0, use inspect.signature() or inspect.getfullargspec()\n",
      "  args, varargs, kw, default = inspect.getargspec(cls.__init__)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/pymorphy2/units/base.py:70: DeprecationWarning: inspect.getargspec() is deprecated since Python 3.0, use inspect.signature() or inspect.getfullargspec()\n",
      "  args, varargs, kw, default = inspect.getargspec(cls.__init__)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/pymorphy2/units/base.py:70: DeprecationWarning: inspect.getargspec() is deprecated since Python 3.0, use inspect.signature() or inspect.getfullargspec()\n",
      "  args, varargs, kw, default = inspect.getargspec(cls.__init__)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/pymorphy2/units/base.py:70: DeprecationWarning: inspect.getargspec() is deprecated since Python 3.0, use inspect.signature() or inspect.getfullargspec()\n",
      "  args, varargs, kw, default = inspect.getargspec(cls.__init__)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/pymorphy2/units/base.py:70: DeprecationWarning: inspect.getargspec() is deprecated since Python 3.0, use inspect.signature() or inspect.getfullargspec()\n",
      "  args, varargs, kw, default = inspect.getargspec(cls.__init__)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/pymorphy2/units/base.py:70: DeprecationWarning: inspect.getargspec() is deprecated since Python 3.0, use inspect.signature() or inspect.getfullargspec()\n",
      "  args, varargs, kw, default = inspect.getargspec(cls.__init__)\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "import pyLDAvis.gensim_models\n",
    "from collections import Counter\n",
    "from string import punctuation\n",
    "from razdel import tokenize as razdel_tokenize\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "from sklearn.decomposition import TruncatedSVD, NMF, PCA, LatentDirichletAllocation\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, TfidfTransformer\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import warnings\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "morph = MorphAnalyzer()\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# добавим лемматизацию\n",
    "def normalize(text):\n",
    "    normalized_text = [word.text.strip(punctuation) for word \\\n",
    "                                                            in razdel_tokenize(text)]\n",
    "    normalized_text = [word.lower() for word in normalized_text if word and len(word) < 20 ]\n",
    "    normalized_text = [morph.parse(word)[0].normal_form for word in normalized_text]\n",
    "    return ' '.join(normalized_text)\n",
    "\n",
    "\n",
    "data = pd.read_csv('avito_category_classification.csv')\n",
    "data['description_norm'] = data['description'].apply(normalize)\n",
    "data = data[:5000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание № 1 (4 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуйте матричные разложения с 5 классификаторами - SGDClassifier, KNeighborsClassifier, MultinomialNB, RandomForest, ExtraTreesClassifier (про него подробнее почитайте в документации, он похож на RF). Используйте и NMF и SVD. Сравните результаты на кросс-валидации и выберите лучшее сочетание.\n",
    "\n",
    "В итоге у вас должно получиться, как минимум 10 моделей (два разложения на каждый классификатор). Используйте 1 и те же параметры кросс-валидации. Параметры векторизации, параметры K в матричных разложениях, параметры классификаторов могут быть разными между экспериментами."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можете взять поменьше данных, если все будет обучаться слишком долго (не ставьте параметр K слишком большим в NMF, иначе точно будет слишком долго)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.decomposition import TruncatedSVD, NMF\n",
    "\n",
    "def eval_table(X, y, pipeline, N=6):\n",
    "    labels = list(set(y))\n",
    "    \n",
    "    fold_metrics = pd.DataFrame(index=labels)\n",
    "    errors = np.zeros((len(labels), len(labels)))\n",
    "    kfold = StratifiedKFold(n_splits=N, shuffle=True, )\n",
    "    \n",
    "    for i, (train_index, test_index) in enumerate(kfold.split(X, y)):\n",
    "        pipeline.fit(X[train_index], y[train_index])\n",
    "        preds = pipeline.predict(X[test_index])\n",
    "        fold_metrics[f'f1_{i}'] = f1_score(y[test_index], preds, labels=labels, average=None)\n",
    "        errors += confusion_matrix(y[test_index], preds, labels=labels)\n",
    "    result = pd.DataFrame(index=labels)\n",
    "\n",
    "    result['f1'] = fold_metrics[[f'f1_{i}' for i in range(N)]].mean(axis=1).round(2)\n",
    "\n",
    "    return result['f1'].iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TruncatedSVD SGD 0.96\n",
      "TruncatedSVD KNN 0.75\n",
      "TruncatedSVD RF 0.7\n",
      "TruncatedSVD ET 0.46\n",
      "NMF SGD 0.89\n",
      "NMF KNN 0.8\n",
      "NMF RF 0.89\n",
      "NMF ET 0.91\n"
     ]
    }
   ],
   "source": [
    "pipelines = []\n",
    "\n",
    "method_dict = {\n",
    "    TruncatedSVD(500): 'TruncatedSVD',\n",
    "    NMF(100): 'NMF'\n",
    "}\n",
    "\n",
    "clf_dict = {\n",
    "    SGDClassifier(): 'SGD', \n",
    "    KNeighborsClassifier(): 'KNN',\n",
    "    RandomForestClassifier(): 'RF', \n",
    "    ExtraTreesClassifier(): 'ET'\n",
    "#     MultinomialNB(): 'MNB'\n",
    "}\n",
    "\n",
    "for method in method_dict.keys():\n",
    "    for clf in clf_dict.keys():\n",
    "        ppln = Pipeline([\n",
    "            ('bow', CountVectorizer(tokenizer=lambda x: x.split(), ngram_range=(1,2), min_df=5, max_df=0.4)),\n",
    "            ('svd', method),\n",
    "            ('clf', clf)\n",
    "        ])\n",
    "        metrics = eval_table(data['description_norm'], data['category_name'], ppln)\n",
    "        print(method_dict[method], '\\t', clf_dict[clf], metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучше справляется комбинация SVD + SGD, далее следуют NMF + SGD и NMF + RF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание № 2 (6 баллов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В Gensim тоже можно добавить нграммы и tfidf. Постройте 1 модель без них (как в семинаре) и еще 3 модели (1 с нграммами, 1 с tfidf и 1 с нграммами и с tfidf). Сранивте качество с помощью метрик (перплексия, когерентность) и на глаз. Определите лучшую модель. Для каждой модели выберите 1 самую красивую на ваш взгляд тему.\n",
    "\n",
    "Используйте данные википедии из семинара. Можете взять поменьше данных, если все обучается долго.\n",
    "\n",
    "Важное требование - получившиеся модели не должны быть совсем плохими. Если хороших тем не получается, попробуйте настроить гиперпараметры, отфильтровать словарь по-другому. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нграммы добавляются вот так (перед созданиеv словаря)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []\n",
    "with open('wiki_data.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        texts.append(f.readline())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [text.split() for text in texts]\n",
    "ph = gensim.models.Phrases(texts, scoring='npmi', threshold=0.4) # threshold можно подбирать\n",
    "p = gensim.models.phrases.Phraser(ph)\n",
    "ngrammed_texts = p[texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Без нграммов и TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: 92522.5679418775\n",
      "Coherence: 0.5632890737006185\n"
     ]
    }
   ],
   "source": [
    "dictinary = gensim.corpora.Dictionary((text for text in texts))\n",
    "dictinary.filter_extremes(no_above=0.1, no_below=10)\n",
    "dictinary.compactify()\n",
    "\n",
    "corpus = [dictinary.doc2bow(text) for text in texts]\n",
    "\n",
    "print(\"Perplexity:\", np.exp2(-lda.log_perplexity(corpus[:1000])))\n",
    "\n",
    "lda_1 = gensim.models.LdaMulticore(corpus, \n",
    "                                 100, # колиество тем\n",
    "                                 alpha='asymmetric',\n",
    "                                 id2word=dictinary, \n",
    "                                 passes=10) \n",
    "\n",
    "topics = []\n",
    "for topic_id, topic in lda_1.show_topics(num_topics=100, formatted=False):\n",
    "    topic = [word for word, _ in topic]\n",
    "    topics.append(topic)\n",
    "\n",
    "coherence_model_lda = gensim.models.CoherenceModel(topics=topics, \n",
    "                                                   texts=[text for text in texts], \n",
    "                                                   dictionary=dictinary, coherence='c_v')\n",
    "\n",
    "print('Coherence:', coherence_model_lda.get_coherence())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(99,\n",
       "  '0.010*\"художник\" + 0.010*\"живописи\" + 0.008*\"века\" + 0.007*\"искусства\" + 0.007*\"в.\" + 0.007*\"картины\" + 0.006*\"Армении\" + 0.006*\"художников\" + 0.005*\"художника\" + 0.005*\"либо\"'),\n",
       " (98,\n",
       "  '0.017*\"СССР\" + 0.005*\"сборной\" + 0.005*\"чемпион\" + 0.004*\"Кубка\" + 0.004*\"бронзовым\" + 0.004*\"матери\" + 0.004*\"получил\" + 0.004*\"призёром\" + 0.004*\"мира\" + 0.004*\"составе\"'),\n",
       " (97,\n",
       "  '0.013*\"ул.\" + 0.007*\"здание\" + 0.005*\"строительства\" + 0.005*\"проекту\" + 0.005*\"части\" + 0.004*\"годов\" + 0.004*\"Н.\" + 0.004*\"000\" + 0.004*\"трамвая\" + 0.004*\"П.\"'),\n",
       " (96,\n",
       "  '0.086*\"г.\" + 0.035*\"гг.\" + 0.020*\"Совета\" + 0.016*\"ЦК\" + 0.014*\"комитета\" + 0.013*\"председатель\" + 0.013*\"заместитель\" + 0.012*\"секретарь\" + 0.012*\"председателя\" + 0.011*\"государственный\"'),\n",
       " (94,\n",
       "  '0.062*\"поселения\" + 0.034*\"территории\" + 0.026*\"сельское\" + 0.024*\"поселение\" + 0.015*\"образование\" + 0.013*\"муниципальное\" + 0.011*\"района\" + 0.011*\"Тверской\" + 0.011*\"центр\" + 0.010*\"сельского\"'),\n",
       " (95,\n",
       "  '0.004*\"полк\" + 0.004*\"июля\" + 0.004*\"войны\" + 0.003*\"через\" + 0.003*\"1919\" + 0.003*\"ноября\" + 0.003*\"получил\" + 0.003*\"октября\" + 0.003*\"августа\" + 0.003*\"15\"'),\n",
       " (93,\n",
       "  '0.028*\"А.\" + 0.023*\"В.\" + 0.015*\"И.\" + 0.014*\"Н.\" + 0.012*\"М.\" + 0.010*\"С.\" + 0.010*\"П.\" + 0.007*\"Г.\" + 0.007*\"награждён\" + 0.006*\"К.\"'),\n",
       " (92,\n",
       "  '0.015*\"1941\" + 0.013*\"войны\" + 0.010*\"мировой\" + 0.010*\"июня\" + 0.010*\"апреля\" + 0.010*\"августа\" + 0.010*\"октября\" + 0.009*\"июля\" + 0.008*\"февраля\" + 0.008*\"Второй\"'),\n",
       " (91,\n",
       "  '0.028*\"провинции\" + 0.022*\"населения\" + 0.013*\"Аргентине\" + 0.010*\"Плотность\" + 0.010*\"расположен\" + 0.010*\"составе\" + 0.010*\"км².\" + 0.009*\"центр\" + 0.009*\"человек\" + 0.009*\"департамент\"'),\n",
       " (90,\n",
       "  '0.014*\"марки\" + 0.014*\"ди\" + 0.010*\"марок\" + 0.009*\"Португалии\" + 0.007*\"почтовых\" + 0.006*\"Дании\" + 0.006*\"1974\" + 0.006*\"почтовой\" + 0.005*\"1975\" + 0.005*\"Canada\"')]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_1.print_topics()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# С нграммами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: 1725370.4906753823\n",
      "Coherence: 0.548494989212285\n"
     ]
    }
   ],
   "source": [
    "dictinary = gensim.corpora.Dictionary((text for text in ngrammed_texts))\n",
    "dictinary.filter_extremes(no_above=0.05, no_below=10)\n",
    "dictinary.compactify()\n",
    "\n",
    "corpus = [dictinary.doc2bow(text) for text in ngrammed_texts]\n",
    "\n",
    "print(\"Perplexity:\", np.exp2(-lda.log_perplexity(corpus[:1000])))\n",
    "\n",
    "\n",
    "lda_2 = gensim.models.LdaMulticore(corpus, \n",
    "                                 100, # колиество тем\n",
    "                                 alpha='asymmetric',\n",
    "                                 id2word=dictinary, \n",
    "                                 passes=10) \n",
    "\n",
    "topics = []\n",
    "for topic_id, topic in lda_2.show_topics(num_topics=100, formatted=False):\n",
    "    topic = [word for word, _ in topic]\n",
    "    topics.append(topic)\n",
    "\n",
    "coherence_model_lda = gensim.models.CoherenceModel(topics=topics, \n",
    "                                                   texts=[text for text in ngrammed_texts], \n",
    "                                                   dictionary=dictinary, coherence='c_v')\n",
    "\n",
    "print('Coherence:', coherence_model_lda.get_coherence())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(99,\n",
       "  '0.015*\"деревня\" + 0.012*\"км_к\" + 0.010*\"дивизия\" + 0.009*\"был_преобразован\" + 0.008*\"дивизии\" + 0.008*\"муниципальное_образование\" + 0.007*\"1_января\" + 0.007*\"1929_году\" + 0.007*\"Алнашском_районе\" + 0.007*\"наделён_статусом\"'),\n",
       " (97,\n",
       "  '0.023*\"подвески\" + 0.019*\"автомобиля\" + 0.009*\"автомобиль\" + 0.008*\"автомобилей\" + 0.005*\"версия\" + 0.005*\"оси\" + 0.005*\"задней\" + 0.005*\"колеса\" + 0.005*\"сравнительно\" + 0.005*\"колесо\"'),\n",
       " (98,\n",
       "  '0.008*\"колхоз\" + 0.008*\"колхоза\" + 0.006*\"центральная_усадьба\" + 0.005*\"ноября_2004\" + 0.005*\"1859\" + 0.004*\"(колхоз)\" + 0.004*\"переименован\" + 0.004*\"проживали\" + 0.004*\"жителей_мужского\" + 0.003*\"вошёл\"'),\n",
       " (96,\n",
       "  '0.008*\"группы\" + 0.008*\"Сергей\" + 0.008*\"песни\" + 0.006*\"Александр\" + 0.005*\"Владимир\" + 0.005*\"Ирина\" + 0.004*\"Игорь\" + 0.004*\"альбом\" + 0.004*\"ансамбль\" + 0.004*\"группа\"'),\n",
       " (94,\n",
       "  '0.010*\"Гитлер\" + 0.006*\"Гитлера\" + 0.005*\"команды.\" + 0.005*\"команды\" + 0.004*\"1998\" + 0.004*\"был_признан\" + 0.004*\"де\" + 0.003*\"()\" + 0.003*\"иезуитов\" + 0.003*\"сборной\"'),\n",
       " (95,\n",
       "  '0.033*\"реки\" + 0.016*\"села\" + 0.014*\"река\" + 0.013*\"реке\" + 0.012*\"территории\" + 0.012*\"районе\" + 0.011*\"расположен\" + 0.010*\"озера\" + 0.010*\"—_село\" + 0.009*\"озеро\"'),\n",
       " (93,\n",
       "  '0.004*\"совхоза\" + 0.003*\"видов\" + 0.003*\"японских\" + 0.003*\"парке\" + 0.003*\"то\" + 0.003*\"«Мир\" + 0.002*\"плато\" + 0.002*\"горные\" + 0.002*\"совхоз\" + 0.002*\"нём\"'),\n",
       " (92,\n",
       "  '0.013*\"район\" + 0.012*\"площади\" + 0.006*\"Ростовской_области\" + 0.005*\"центр\" + 0.005*\"до_н.\" + 0.004*\"первая\" + 0.004*\"по_проекту\" + 0.004*\"архитектора\" + 0.004*\"была_построена\" + 0.004*\"—_административно-территориальная\"'),\n",
       " (90,\n",
       "  '0.011*\"А.\" + 0.008*\"И.\" + 0.007*\"С.\" + 0.007*\"В.\" + 0.006*\"Н.\" + 0.005*\"М.\" + 0.005*\"Г.\" + 0.004*\"Д.\" + 0.003*\"Л.\" + 0.003*\"Е.\"'),\n",
       " (91,\n",
       "  '0.003*\"катастрофы\" + 0.003*\"борту\" + 0.003*\"рейс\" + 0.003*\"В._П.\" + 0.003*\"1979\" + 0.003*\"The\" + 0.003*\"к_чемпионату\" + 0.003*\"февраля\" + 0.003*\"1990\" + 0.003*\"родился\"')]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_2.print_topics()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# С TF–IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: 1.2862625919507363e+61\n",
      "Coherence: 0.4114695081463832\n"
     ]
    }
   ],
   "source": [
    "dictinary = gensim.corpora.Dictionary((text for text in texts))\n",
    "dictinary.filter_extremes(no_above=0.01, no_below=10)\n",
    "dictinary.compactify()\n",
    "\n",
    "corpus = [dictinary.doc2bow(text) for text in texts]\n",
    "\n",
    "tfidf = gensim.models.TfidfModel(corpus, id2word=dictinary, smartirs='lfc')\n",
    "corpus = tfidf[corpus]\n",
    "\n",
    "print(\"Perplexity:\", np.exp2(-lda.log_perplexity(corpus[:1000])))\n",
    "\n",
    "lda_3 = gensim.models.LdaMulticore(corpus, \n",
    "                                 100, # колиество тем\n",
    "                                 alpha='asymmetric',\n",
    "                                 id2word=dictinary, \n",
    "                                 passes=10) \n",
    "\n",
    "topics = []\n",
    "for topic_id, topic in lda_3.show_topics(num_topics=100, formatted=False):\n",
    "    topic = [word for word, _ in topic]\n",
    "    topics.append(topic)\n",
    "\n",
    "coherence_model_lda = gensim.models.CoherenceModel(topics=topics, \n",
    "                                                   texts=[text for text in texts], \n",
    "                                                   dictionary=dictinary, coherence='c_v')\n",
    "\n",
    "print('Coherence:', coherence_model_lda.get_coherence())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(99,\n",
       "  '0.000*\"Billboard\" + 0.000*\"поднялся\" + 0.000*\"барабанщика\" + 0.000*\"альбомов,\" + 0.000*\"соло\" + 0.000*\"одноименной\" + 0.000*\"композиция\" + 0.000*\"Майкл\" + 0.000*\"коллектива\" + 0.000*\"годами\"'),\n",
       " (98,\n",
       "  '0.009*\"IBM\" + 0.000*\"F\" + 0.000*\"во-первых,\" + 0.000*\"печатный\" + 0.000*\"признаётся\" + 0.000*\"латинских\" + 0.000*\"T\" + 0.000*\"возродить\" + 0.000*\"U\" + 0.000*\"даны\"'),\n",
       " (97,\n",
       "  '0.000*\"судно\" + 0.000*\"судном\" + 0.000*\"верфи\" + 0.000*\"пассажирский\" + 0.000*\"продана\" + 0.000*\"корабль\" + 0.000*\"корабля\" + 0.000*\"покинула\" + 0.000*\"пассажирских\" + 0.000*\"вокзала\"'),\n",
       " (96,\n",
       "  '0.000*\"записал\" + 0.000*\"совместный\" + 0.000*\"альбомов\" + 0.000*\"итальянской\" + 0.000*\"del\" + 0.000*\"La\" + 0.000*\"написаны\" + 0.000*\"песню\" + 0.000*\"музыки\" + 0.000*\"(1994),\"'),\n",
       " (95,\n",
       "  '0.007*\"мост\" + 0.000*\"мосту\" + 0.000*\"моста\" + 0.000*\"ограждение\" + 0.000*\"сечения\" + 0.000*\"юга\" + 0.000*\"моста.\" + 0.000*\"завершается\" + 0.000*\"архитектурные\" + 0.000*\"речки\"'),\n",
       " (93,\n",
       "  '0.010*\"серебряных\" + 0.000*\"Речи\" + 0.000*\"германских\" + 0.000*\"долгие\" + 0.000*\"Город\" + 0.000*\"Римским\" + 0.000*\"средневековой\" + 0.000*\"погибло\" + 0.000*\"владений,\" + 0.000*\"независимости.\"'),\n",
       " (94,\n",
       "  '0.089*\"Токио\" + 0.020*\"китайская\" + 0.006*\"Тан\" + 0.002*\"Сун,\" + 0.000*\"периода.\" + 0.000*\"выражения\" + 0.000*\"дядя\" + 0.000*\"Эда\" + 0.000*\"поэмы\" + 0.000*\"Рудольфа\"'),\n",
       " (92,\n",
       "  '0.000*\"судебных\" + 0.000*\"замок\" + 0.000*\"судебной\" + 0.000*\"замка\" + 0.000*\"делу\" + 0.000*\"1868\" + 0.000*\"башня\" + 0.000*\"восстановлены\" + 0.000*\"башни\" + 0.000*\"Южная\"'),\n",
       " (91,\n",
       "  '0.000*\"Фёдорович\" + 0.000*\"экзамен\" + 0.000*\"Нижегородской\" + 0.000*\"журнале\" + 0.000*\"генерала\" + 0.000*\"70-х\" + 0.000*\"литературного\" + 0.000*\"местной\" + 0.000*\"способность\" + 0.000*\"генералу\"'),\n",
       " (90,\n",
       "  '0.000*\"парка\" + 0.000*\"Таврической\" + 0.000*\"экспедиции\" + 0.000*\"парк\" + 0.000*\"пройти\" + 0.000*\"Иванов\" + 0.000*\"генерал-губернатора\" + 0.000*\"памятников\" + 0.000*\"канадским\" + 0.000*\"фестиваля\"')]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_3.print_topics()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# С нграммами и TF–IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: 1.959383564087525e+50\n",
      "Coherence: 0.4139797118671423\n"
     ]
    }
   ],
   "source": [
    "dictinary = gensim.corpora.Dictionary((text for text in ngrammed_texts))\n",
    "dictinary.filter_extremes(no_above=0.05, no_below=10)\n",
    "dictinary.compactify()\n",
    "\n",
    "corpus = [dictinary.doc2bow(text) for text in ngrammed_texts]\n",
    "\n",
    "tfidf = gensim.models.TfidfModel(corpus, id2word=dictinary, smartirs='lfc')\n",
    "corpus = tfidf[corpus]\n",
    "\n",
    "print(\"Perplexity:\", np.exp2(-lda.log_perplexity(corpus[:1000])))\n",
    "\n",
    "lda_4 = gensim.models.LdaMulticore(corpus, \n",
    "                                 50, # колиество тем\n",
    "                                 alpha='asymmetric',\n",
    "                                 id2word=dictinary, \n",
    "                                 passes=10) \n",
    "\n",
    "topics = []\n",
    "for topic_id, topic in lda_4.show_topics(num_topics=100, formatted=False):\n",
    "    topic = [word for word, _ in topic]\n",
    "    topics.append(topic)\n",
    "\n",
    "coherence_model_lda = gensim.models.CoherenceModel(topics=topics, \n",
    "                                                   texts=[text for text in ngrammed_texts], \n",
    "                                                   dictionary=dictinary, coherence='c_v')\n",
    "\n",
    "print('Coherence:', coherence_model_lda.get_coherence())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(49,\n",
       "  '0.000*\"открытым\" + 0.000*\"были_сняты\" + 0.000*\"был_снят\" + 0.000*\"1889\" + 0.000*\"Снят\" + 0.000*\"длился\" + 0.000*\"Джей\" + 0.000*\"села\" + 0.000*\"игра\" + 0.000*\"ранее.\"'),\n",
       " (48,\n",
       "  '0.000*\"Марии\" + 0.000*\"заметных\" + 0.000*\"сотрудничать\" + 0.000*\"Кристина\" + 0.000*\"факультет,\" + 0.000*\"начала_работать\" + 0.000*\"государственный_университет\" + 0.000*\"простое\" + 0.000*\"игровом\" + 0.000*\"документального\"'),\n",
       " (47,\n",
       "  '0.000*\"вождя\" + 0.000*\"Узнав_об\" + 0.000*\"продвинулся\" + 0.000*\"добычей\" + 0.000*\"столицу,\" + 0.000*\"отступили\" + 0.000*\"вторжение\" + 0.000*\"вторглись\" + 0.000*\"период,\" + 0.000*\"закончилось\"'),\n",
       " (46,\n",
       "  '0.000*\"был,\" + 0.000*\"ты\" + 0.000*\"наладить\" + 0.000*\"Советский\" + 0.000*\"контакты\" + 0.000*\"аэропорт\" + 0.000*\"разгрома\" + 0.000*\"разведки\" + 0.000*\"входящих\" + 0.000*\"Великой_Отечественной\"'),\n",
       " (45,\n",
       "  '0.000*\"прочие\" + 0.000*\"стиле\" + 0.000*\"комедия\" + 0.000*\"сооружений,\" + 0.000*\"всякий\" + 0.000*\"решается\" + 0.000*\"охотников\" + 0.000*\"лишним\" + 0.000*\"творческий\" + 0.000*\"романтическая\"'),\n",
       " (44,\n",
       "  '0.000*\"Высшую\" + 0.000*\"Белоруссии\" + 0.000*\"лигу\" + 0.000*\"Республики_Беларусь\" + 0.000*\"классический\" + 0.000*\"по_футболу\" + 0.000*\"выселок\" + 0.000*\"минского\" + 0.000*\"2-е_место\" + 0.000*\"Высшей_лиге\"'),\n",
       " (43,\n",
       "  '0.000*\"бронзовым_призёром\" + 0.000*\"диагностики\" + 0.000*\"монографий,\" + 0.000*\"Жуки\" + 0.000*\"стандартов\" + 0.000*\"медицинского\" + 0.000*\"научную\" + 0.000*\"разработчиков\" + 0.000*\"более_600\" + 0.000*\"лабораторию\"'),\n",
       " (42,\n",
       "  '0.000*\"защитил_диссертацию\" + 0.000*\"теме\" + 0.000*\"Правительства_Российской\" + 0.000*\"получил_степень\" + 0.000*\"русского_языка\" + 0.000*\"врач\" + 0.000*\"степени_доктора\" + 0.000*\"«Русская\" + 0.000*\"дружбы\" + 0.000*\"главный\"'),\n",
       " (41,\n",
       "  '0.000*\"погиб,\" + 0.000*\"был_сбит\" + 0.000*\"вызывало\" + 0.000*\"хвоста\" + 0.000*\"парке\" + 0.000*\"работы\" + 0.000*\"евреев\" + 0.000*\"особей\" + 0.000*\"майор\" + 0.000*\"сахарного\"'),\n",
       " (40,\n",
       "  '0.000*\"Вологде\" + 0.000*\"подтверждено\" + 0.000*\"третий_студийный\" + 0.000*\"«The\" + 0.000*\"декабре_2009\" + 0.000*\"Top\" + 0.000*\"московский\" + 0.000*\"Великом\" + 0.000*\"повелению\" + 0.000*\"духовенства\"'),\n",
       " (9,\n",
       "  '0.002*\"город.\" + 0.000*\"создавалась\" + 0.000*\"судов.\" + 0.000*\"тридцати\" + 0.000*\"топлива,\" + 0.000*\"грузовые\" + 0.000*\"поставку\" + 0.000*\"наземных\" + 0.000*\"вызванных\" + 0.000*\"по_предложению\"'),\n",
       " (8,\n",
       "  '0.001*\"11_октября\" + 0.001*\"меньших\" + 0.001*\"волос\" + 0.001*\"птица\" + 0.001*\"волосы\" + 0.001*\"(дочь\" + 0.001*\"(о\" + 0.001*\"древнегреческой\" + 0.001*\"ткани\" + 0.001*\"упоминает\"'),\n",
       " (7,\n",
       "  '0.010*\"географических\" + 0.004*\"Происходит\" + 0.003*\"распространено\" + 0.002*\"поселений,\" + 0.002*\"имя\" + 0.002*\"виде\" + 0.002*\"De\" + 0.002*\"водой\" + 0.002*\"сельских\" + 0.001*\"буквами\"'),\n",
       " (6,\n",
       "  '0.003*\"железнодорожного\" + 0.001*\"истории\" + 0.001*\"балетной\" + 0.001*\"появлялся\" + 0.001*\"Альберто\" + 0.001*\"1997\" + 0.001*\"оболочки\" + 0.001*\"Одесской\" + 0.001*\"шириной_около\" + 0.001*\"Малой\"'),\n",
       " (5,\n",
       "  '0.007*\"/\" + 0.006*\"обыграли\" + 0.005*\"со_счётом\" + 0.003*\"обыграл\" + 0.002*\"языках,\" + 0.002*\"кортах\" + 0.002*\"серии_ATP\" + 0.002*\"во_многих\" + 0.001*\"армянский\" + 0.001*\"турнир\"'),\n",
       " (4,\n",
       "  '0.005*\"символ\" + 0.003*\"длине_2:3,\" + 0.003*\"см_длиной,\" + 0.003*\"(фильм,\" + 0.003*\"см_длиной\" + 0.003*\"полотнища\" + 0.003*\"цвет_(золото)\" + 0.003*\"Михаил\" + 0.003*\"муниципального_района\" + 0.003*\"флаге\"'),\n",
       " (3,\n",
       "  '0.006*\"стадионе\" + 0.006*\"матчи_проводит\" + 0.006*\"городской_округ\" + 0.006*\"вмещающем\" + 0.005*\"построенных_для\" + 0.005*\"спущен\" + 0.005*\"имя\" + 0.005*\"строй\" + 0.005*\"делится\" + 0.005*\"Российского_Императорского\"'),\n",
       " (2,\n",
       "  '0.015*\"сельское_поселение\" + 0.011*\"может\" + 0.011*\"муниципальное_образование\" + 0.009*\"(\" + 0.008*\"сельское\" + 0.008*\"Воронежской_области.############Административный\" + 0.008*\"состав_поселения\" + 0.008*\"центр\" + 0.007*\"населенных\" + 0.007*\"—_село\"'),\n",
       " (1,\n",
       "  '0.003*\"клуб\" + 0.003*\"финале\" + 0.002*\"со_счётом\" + 0.002*\"провёл\" + 0.002*\"команды\" + 0.002*\"по_снукеру\" + 0.002*\"сезоне\" + 0.002*\"чемпионате\" + 0.002*\"перешёл\" + 0.002*\"клуба\"'),\n",
       " (0,\n",
       "  '0.002*\"коммуны\" + 0.002*\"ни_одной\" + 0.001*\"историю,_но\" + 0.001*\"принимала_участие\" + 0.001*\"Житомирской_области.############Код\" + 0.001*\"человек._Почтовый\" + 0.001*\"тел.\" + 0.001*\"не_завоевала\" + 0.001*\"принимал_участие\" + 0.001*\"коммуна\"')]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_4.print_topics()[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tfidf добавляется вот так (после векторизации и перед обучением lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Результаты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Темы\n",
    "Все модели периодически выдают интересные темы, вот список тем, которые показались мне интересными:\n",
    "\n",
    "'0.010*\"художник\" + 0.010*\"живописи\" + 0.008*\"века\" + 0.007*\"искусства\" + 0.007*\"в.\" + 0.007*\"картины\" + 0.006*\"Армении\" + 0.006*\"художников\" + 0.005*\"художника\" + 0.005*\"либо\"'),\n",
    "\n",
    "'0.004*\"полк\" + 0.004*\"июля\" + 0.004*\"войны\" + 0.003*\"через\" + 0.003*\"1919\" + 0.003*\"ноября\" + 0.003*\"получил\" + 0.003*\"октября\" + 0.003*\"августа\" + 0.003*\"15\"'),\n",
    "\n",
    "'0.014*\"марки\" + 0.014*\"ди\" + 0.010*\"марок\" + 0.009*\"Португалии\" + 0.007*\"почтовых\" + 0.006*\"Дании\" + 0.006*\"1974\" + 0.006*\"почтовой\" + 0.005*\"1975\" + 0.005*\"Canada\"')]\n",
    "\n",
    "  '0.023*\"подвески\" + 0.019*\"автомобиля\" + 0.009*\"автомобиль\" + 0.008*\"автомобилей\" + 0.005*\"версия\" + 0.005*\"оси\" + 0.005*\"задней\" + 0.005*\"колеса\" + 0.005*\"сравнительно\" + 0.005*\"колесо\"'),\n",
    "\n",
    "  '0.000*\"Billboard\" + 0.000*\"поднялся\" + 0.000*\"барабанщика\" + 0.000*\"альбомов,\" + 0.000*\"соло\" + 0.000*\"одноименной\" + 0.000*\"композиция\" + 0.000*\"Майкл\" + 0.000*\"коллектива\" + 0.000*\"годами\"'),\n",
    "\n",
    "## Перплексия\n",
    "Без всего: 92522.5679418775\n",
    "\n",
    "Нграммы: 1725370.4906753823\n",
    "\n",
    "TF–IDF: 1.2862625919507363e+61\n",
    "\n",
    "Нграммы + TF–IDF: 1.959383564087525e+50\n",
    "\n",
    "## Когерентность\n",
    "Без всего: 0.5632890737006185\n",
    "\n",
    "Нграммы: 0.548494989212285\n",
    "\n",
    "TF–IDF: 0.4114695081463832 \n",
    "\n",
    "Нграммы + TF–IDF: 0.4139797118671423\n",
    "\n",
    "В моделях с использованием нграммов / TF–IDF снижается качество метрик, но некоторые темы становятся более точными"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
